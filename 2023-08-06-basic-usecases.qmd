---
title: "Basic use cases of the `nonprobsvy` package"
author: Maciej Beręsewicz, Łukasz Chrostowski
format: 
  html:
    number-sections: true
    self-contained: true
    toc: true
    df-print: kable
lang: en
bibliography: references.bib
biblio-style: apalike
execute: 
  warning: false
  cache: false
  message: false
---

# Introduction

This tutorial shows basic usage of the
[nonprobsvy](https://github.com/ncn-foreigners/nonprobsvy) package
developed in this project based on example from the paper 

```
Yang, S., Kim, J. K., & Song, R. (2020). Doubly robust inference 
when combining probability and non-probability samples with high
dimensional data. Journal of the Royal Statistical Society. Series
B, Statistical Methodology, 82(2), 445.
```
    
# Install and load the required packages

Install `remotes` package and then install `nonprobsvy` package from
github repository.

```{r install-packages, eval=FALSE}
install.packages("remotes")
remotes::install_github("ncn-foreigners/nonprobsvy")
install.packages("survey")
install.packages("sampling")
```

```{r}
library(sampling)
library(survey)
library(nonprobsvy)
```


# Basic setup

We create the data according to the following recipe:

+ $N=10000$  -- population size,
+ $p=50$-- number of $X_p$ variables where $p-1$ were generated from $N(0,1)$ distribution,
+ $A$ - probability sample about $n_A \approx 500$,
+ $B$ - nonprobability sample of size about $n_B \approx 2000$,
+ selection:
  + $A \propto (0.25 + |X_{1i}| + 0.03|Y_i|$,
  + $B$ selected according to model $\text{logit}(3.5 + \mathbf{\alpha}^T(\log(\mathbf{X}_i)^2) - \sin(X_{3i} + X_{4i}) - X_{5i} - X_{6i})$ where $\mathbf{\alpha}=(0,0,0,3,3,3,3,0,...,0)^T$,
+ $Y$ generated according to the following model: 

$$
Y_i = 1 + \exp(3\sin(\mathbf{\beta}^T\mathbf{X}_i)) + X_{5i} + X_{6i} + \epsilon,
$$
where $\mathbf{\beta}=(1,0,0,1,1,1,1,0,...,0)^T$.

```{r}
set.seed(2023-7-6)
N <- 10000
n_A <- 500
p <- 50
alpha_vec1 <- c(-2, 1, 1, 1,1, rep(0, p-5))
alpha_vec2 <- c(0,0,0,3,3,3,3, rep(0, p-7))
beta_vec <- c(1,0,0,1,1,1,1, rep(0, p-7))
X <- cbind("(Intercept)"=1, matrix(rnorm(N*(p-1)), nrow=N, byrow=T, dimnames = list(NULL, paste0("X",1:(p-1)))))
#Y <- 1 + as.numeric(X %*% beta_vec) +   rnorm(N)
Y <- 1+ exp(3*sin(as.numeric(X %*% beta_vec))) + X[, "X5"] + X[, "X6"] + rnorm(N)
pi_B <- plogis(as.numeric(X %*% alpha_vec1))
#pi_B <- plogis(3.5 + as.numeric(log(X^2) %*% alpha_vec2) - sin(X[, "X3"] + X[, "X4"]) - X[,"X5"] + X[, "X6"])
flag_B <- rbinom(N, 1, prob = pi_B)
pi_A <- inclusionprobabilities(0.25 + abs(X[, "X1"]) + 0.03*abs(Y), n_A)
flag_A <- UPpoisson(pik = pi_A)
pop_data <- data.frame(pi_A, pi_B, flag_A, flag_B, Y, X[, 2:p])

## population totals
X_totals <- colSums(X)
X_means <- colMeans(X[,-1])
sample_A_svy <- svydesign(ids = ~ 1, probs = ~ pi_A, pps = "brewer", data = pop_data[pop_data$flag_A == 1, ])
sample_A_svy_cal <- calibrate(sample_A_svy, 
                              formula = as.formula(paste0("~", paste(names(X_totals)[2:p], collapse = "+"))),
                              population = X_totals, 
                              calfun = cal.raking)
sample_B <- pop_data[pop_data$flag_B == 1, ]
## true Y
y_true <- mean(Y)
```

# Population level data is only available

## Inverse probability weighting

First, we start with IPW calibrated to population totals using `mle`

```{r ipw-basic-pop-totals}
m1 <- nonprob(selection = ~ X1+X2+X3+X4,
              target = ~ Y,
              data = sample_B,
              pop_totals = X_totals[1:5],
              method_selection = "logit")
summary(m1)
```
We can change optimizer through `control_selection` argument and `controlSel` function

```{r ipw-basic-pop-totals-optim}
m1a <- nonprob(selection = ~ X1+X2+X3+X4,
              target = ~ Y,
              data = sample_B,
              pop_totals = X_totals[1:5], 
              control_selection = controlSel(optimizer = "optim"))
summary(m1a)
```

We can change estimation method to generalized estimating equations (`gee`) through `control_selection` argument and `controlSel` function. We can also change $h$ function to 1 ($X/\pi(X,\alpha)$) or 2 ($X$).

```{r ipw-basic-pop-totals-gee}
m1b <- nonprob(selection = ~ X1+X2+X3+X4,
              target = ~ Y,
              data = sample_B,
              pop_totals = X_totals[1:5], 
              control_selection = controlSel(optimizer = "optim", est_method_sel = "gee", h=2)) ## for h=1 - NaNs
summary(m1b)
```
It may happen that instead of `pop_totals` we know population means but population size should be known [**NOT WORKING**]

```{r ipw-basic-pop-means,eval=FALSE}
m1c <- nonprob(selection = ~ X1+X2+X3+X4,
              target = ~ Y,
              data = sample_B,
              pop_means =  X_means[1:4],
              pop_size = N,
              method_selection = "logit")
summary(m1c)
```


## Mass imputation (TBA)

```{r}
m1 <- nonprob(outcome = Y ~ X3 + X4 + X5 + X6,
              data = sample_B,
              #pop_totals = X_totals[1:5],
              svydesign = sample_A_svy_cal,
              method_outcome = "glm",
              family_outcome = "gaussian")
summary(m1)
```


## Doubly robust (TBA)

```{r eval=FALSE, echo=FALSE}
library(jointCalib)
pop_totals2 <- X_totals[c("X1", "X2", "X3", "X4", "X5", "X6")]
pop_quants <- lapply(as.data.frame(X[, c("X1", "X2", "X3", "X4","X5", "X6")]), 
                     quantile, 
                     #probs = c(0.1, 0.5, 0.9)
                     probs = seq(0.1, 0.9, 0.1)
                     )

qcal1 <- joint_calib(formula_quantiles = ~ X1 + X2 + X3 + X4 + X5 + X6,
                    #formula_totals = ~ X3 + X4 + X5 + X6,
                    data = sample_B, 
                    dweights = rep(N/nrow(sample_B), nrow(sample_B)),
                    #pop_totals = pop_totals2,
                    pop_quantiles = pop_quants,
                    N = N,
                    method = "raking")

qcal2 <- joint_calib(formula_quantiles = ~ X1 + X2 + X3 + X4 + X5 + X6,
                    formula_totals = ~ X1 + X2 + X3 + X4 + X5 + X6,
                    data = sample_B, 
                    dweights = rep(N/nrow(sample_B), nrow(sample_B)),
                    pop_totals = pop_totals2,
                    pop_quantiles = pop_quants,
                    N = N,
                    method = "raking")

res <- calib(Xs = model.matrix(~ X1 + X2 + X3 + X4 + X5 + X6, sample_B), 
             d = rep(N/nrow(sample_B), nrow(sample_B)), 
             total = c(N,pop_totals2),
             method = "raking")

c(naive = mean(sample_B$Y),
  greg = weighted.mean(sample_B$Y, res),
  qcal1 = weighted.mean(sample_B$Y, qcal1$g),
  qcal1 = weighted.mean(sample_B$Y, qcal2$g),
  true = y_true) 
```


# Probability sample is available


# Variable selection

## IPW

We can do variable selection (**but here it is not working???**)

```{r, eval = F, echo=T}
m1 <- nonprob(selection = ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10,
              target = ~ Y,
              data = sample_B,
              pop_totals = X_totals[1:11],
              #svydesign = sample_A_svy_cal,
              method_selection = "logit",
              control_inference = controlInf(vars_selection = TRUE),
              control_selection = controlSel(penalty = "SCAD"))
summary(m1)
```

