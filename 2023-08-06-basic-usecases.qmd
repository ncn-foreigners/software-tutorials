---
title: "Basic use cases of the `nonprobsvy` package"
author: Maciej Beręsewicz, Łukasz Chrostowski
format: 
  html:
    number-sections: true
    self-contained: true
    toc: true
    df-print: kable
lang: en
bibliography: references.bib
biblio-style: apalike
execute: 
  warning: false
  cache: false
  message: false
---

# Introduction

This tutorial shows basic usage of the
[nonprobsvy](https://github.com/ncn-foreigners/nonprobsvy) package
developed in this project based on example from the paper 

```
Yang, S., Kim, J. K., & Song, R. (2020). Doubly robust inference 
when combining probability and non-probability samples with high
dimensional data. Journal of the Royal Statistical Society. Series
B, Statistical Methodology, 82(2), 445.
```

All technical details regarding implementation can be found [here](https://ncn-foreigners.github.io/nonprobsvy-book/)
    
    
## Basic information regarding the package

Package implements the following approaches:

+ inverse probability weighting / propensity score weighting / adjustment estimator with covariate balancing / calibration constraints, 
+ mass imputation estimator (nearest neighbour, model-based),
+ doubly robust estimator (including bias minimization),
+ variace for probability sample is estimated using `survey` package.

In addition:

 + allows to select variables using `SCAD`, `lasso` and `MCP` penalties,
 + allows for inference when only population totals, means and size is available,
 + variance is estimated using analytical and bootstrap approach.
 

Currently only `glm` models are implemented (i.e. gaussian, binomial, poisson).

## Install and load the required packages

Install `remotes` package and then install `nonprobsvy` package from
github repository.

```{r install-packages, eval=FALSE}
install.packages("remotes")
remotes::install_github("ncn-foreigners/nonprobsvy")
install.packages("survey")
install.packages("sampling")
```

Load required packages

```{r load-packages}
library(sampling)
library(survey)
library(nonprobsvy)
library(ggplot2)
```


## Basic setup for examples

We generate the data using the following recipe:

+ $N=10000$  -- population size,
+ $p=50$ -- number of $X_p$ variables where $p-1$ were generated from $N(0,1)$ distribution,
+ $A$ -- probability sample about $n_A \approx 500$,
+ $B$ -- nonprobability sample of size about $n_B \approx 2000$,
+ selection:
  + $A \propto 0.25 + |X_{1i}| + 0.03|Y_i|$,
  + $B$ selected according to model
  
  $$
  \text{logit}(\pi_{B,i}) =\mathbf{\alpha}^TX_i %(3.5 + \mathbf{\alpha}^T(\log(\mathbf{X}_i)^2) - \sin(X_{3i} + X_{4i}) - X_{5i} - X_{6i}),
  $$ 
  
  where $\mathbf{\alpha}=(0,0,0,3,3,3,3,0,...,0)^T$,
+ $Y$ generated according to the following model: 

$$
Y_i = 1 + \exp(3\sin(\mathbf{\beta}^T\mathbf{X}_i)) + X_{5i} + X_{6i} + \epsilon,
$$

where $\mathbf{\beta}=(1,0,0,1,1,1,1,0,...,0)^T$. 

```{r generate-data}
seed_for_sim <- 2023-8-15
set.seed(seed_for_sim)
N <- 10000
n_A <- 500
p <- 50
alpha_vec1 <- c(-2, 1, 1, 1,1, rep(0, p-5))
alpha_vec2 <- c(0,0,0,3,3,3,3, rep(0, p-7))
beta_vec <- c(1,0,0,1,1,1,1, rep(0, p-7))
X <- cbind("(Intercept)"=1, matrix(rnorm(N*(p-1)), nrow=N, byrow=T, dimnames = list(NULL, paste0("X",1:(p-1)))))
#Y <- 1 + as.numeric(X %*% beta_vec) +   rnorm(N) ## linear model
Y <- 1 + exp(3*sin(as.numeric(X %*% beta_vec))) + X[, "X5"] + X[, "X6"] + rnorm(N) ## nonlinear model
pi_B <- plogis(as.numeric(X %*% alpha_vec1)) ## linear probability
#pi_B <- plogis(3.5 + as.numeric(log(X^2) %*% alpha_vec2) - sin(X[, "X3"] + X[, "X4"]) - X[,"X5"] + X[, "X6"]) ## nonlinear probability
flag_B <- rbinom(N, 1, prob = pi_B)
pi_A <- inclusionprobabilities(0.25 + abs(X[, "X1"]) + 0.03*abs(Y), n_A)
flag_A <- UPpoisson(pik = pi_A)
pop_data <- data.frame(pi_A, pi_B, flag_A, flag_B, Y, X[, 2:p])
```

We calibrate probability sample `A` to known population totals and set `svydesign` with `pps=brewer`.

```{r calibrate-prob-sample}
## population totals
X_totals <- colSums(X)
X_means <- colMeans(X[,-1])
sample_A_svy <- svydesign(ids = ~ 1, probs = ~ pi_A, pps = "brewer", data = pop_data[pop_data$flag_A == 1, ])
sample_A_svy_cal <- calibrate(sample_A_svy, 
                              formula = as.formula(paste0("~", paste(names(X_totals)[2:p], collapse = "+"))),
                              population = X_totals, 
                              calfun = cal.raking)
```

Then we select nonprobability sample `B` using probability based on `flag_B` variable.

```{r generate-nonprob}
sample_B <- pop_data[pop_data$flag_B == 1, ]
sample_B$dweight <- N/nrow(sample_B)
```

True mean of `Y`.

```{r true-y}
y_true <- mean(Y)
y_true
```

# Inverse probability weighting estimator

First, we start with [inverse probability weighting estimator](https://ncn-foreigners.github.io/nonprobsvy-book/ipw.html) under different settings. 

## Only population information is available

Note that standard error is under-estimated as assume that `pop_totals` is known, not estimated. Here we use `mle` with calibration constraints [see mle in the documentation](https://ncn-foreigners.github.io/nonprobsvy-book/ipw.html#maximum-likelihood-estimation).

```{r ipw-pop-totals}
ipw_logit_poptotals <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                               target = ~ Y,
                               data = sample_B,
                               pop_totals = X_totals[1:5],
                               method_selection = "logit")

cbind(ipw_logit_poptotals$output,ipw_logit_poptotals$confidence_interval)
```

We can change from `mle` to `gee` with different definitions of $h$ function (1 for $X/\pi(X,\alpha)$ or 2 for $X$). See [documentation for gee](https://ncn-foreigners.github.io/nonprobsvy-book/ipw.html#general-estimating-equations).


```{r ipw-pop-totals-gee}
ipw_logit_poptotals_gee <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                                   target = ~ Y,
                                   data = sample_B,
                                   pop_totals = X_totals[1:5],
                                   method_selection = "logit",
                                   control_selection = controlSel(est_method_sel = "gee", h_x = 1))

cbind(ipw_logit_poptotals_gee$output,ipw_logit_poptotals_gee$confidence_interval)
```
Finally, we can conduct variable selection using `SCAD` under different models

```{r ipw-pop-totals-scad}
ipw_logit_poptotals_scad <- nonprob(selection = ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                                   target = ~ Y,
                                   data = sample_B,
                                   pop_totals = X_totals[1:11],
                                   method_selection = "logit",
                                   control_selection = controlSel(penalty = "SCAD"),
                                   control_inference = controlInf(vars_selection = TRUE))

cbind(ipw_logit_poptotals_scad$output,ipw_logit_poptotals_scad$confidence_interval)
```
Only X1 was selected, but note that changing the order of auxiliary variables other variable(s) may be selected.

```{r ipw-pop-totals-scad-coef}
summary(ipw_logit_poptotals_scad)$coef
```

## Probability sample is available

Now consider the case when probability sample is available.

```{r ipw-sample}
ipw_logit_sample <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                               target = ~ Y,
                               data = sample_B,
                               svydesign = sample_A_svy_cal,
                               method_selection = "logit")

cbind(ipw_logit_sample$output,ipw_logit_sample$confidence_interval)
```
Now change to `gee` as previously

```{r ipw-sample-gee}
ipw_logit_sample_gee <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                                target = ~ Y,
                                data = sample_B,
                                svydesign = sample_A_svy_cal,
                                method_selection = "logit",
                                control_selection = controlSel(est_method_sel = "gee", h_x = 1))

cbind(ipw_logit_sample_gee$output,ipw_logit_sample_gee$confidence_interval)
```
Moreover if we have sample we can estimate variance using bootstrap. Note that boostrap for probability sample is coducted using `survey::as.svrepdesign`.

```{r ipw-sample-gee-boot}
set.seed(seed_for_sim)
ipw_logit_sample_gee_boot <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                                     target = ~ Y,
                                     data = sample_B,
                                     svydesign = sample_A_svy_cal,
                                     method_selection = "logit",
                                     control_selection = controlSel(est_method_sel = "gee", h_x = 1),
                                     control_inference = controlInf(var_method = "bootstrap", num_boot = 100))

cbind(ipw_logit_sample_gee_boot$output,ipw_logit_sample_gee_boot$confidence_interval)
```
And finally conduct variables selection and combine it with bootstrap variance estimator.

```{r ipw-sample-scad}
ipw_logit_sample_scad <- nonprob(selection = ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                                 target = ~ Y,
                                 data = sample_B,
                                 svydesign = sample_A_svy_cal,
                                 method_selection = "logit",
                                 control_selection = controlSel(penalty = "SCAD"),
                                 control_inference = controlInf(vars_selection = TRUE,
                                                                var_method = "bootstrap", 
                                                                num_boot = 50))

cbind(ipw_logit_sample_scad$output,ipw_logit_sample_scad$confidence_interval)
```
The output of procedures is similar to glm

```{r ipw-sample-scad-summary}
summary(ipw_logit_sample_scad)
```
# Mass imputation estimator

Now, we start with [mass imputation estimator](https://ncn-foreigners.github.io/nonprobsvy-book/mi.html) under different settings. 

## Only population information is available

In the examples we assume that $f(Y|X)$ is linear so the estimator will be biased as model is mis-specified.

```{r mi-pop-totals}
mi_poptotals <- nonprob(outcome = Y ~ X3 + X4 + X5 + X6,
                        data = sample_B,
                        pop_totals = X_totals[c("(Intercept)", "X3", "X4", "X5", "X6")],
                        method_outcome = "glm",
                        family_outcome = "gaussian")

cbind(mi_poptotals$output,mi_poptotals$confidence_interval)
```

## Probability sample is available

Now, consider that sample

```{r mi-sample}
mi_sample <- nonprob(outcome = Y ~ X3 + X4 + X5 + X6,
                     data = sample_B,
                     svydesign = sample_A_svy_cal,
                     method_outcome = "glm",
                     family_outcome = "gaussian")

cbind(mi_sample$output,mi_sample$confidence_interval)
```

We can select variables using SCAD penalty [currently not working]

```{r mi-sample-scad}
mi_sample_scad <- nonprob(outcome = Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                     data = sample_B,
                     svydesign = sample_A_svy_cal,
                     method_outcome = "glm",
                     family_outcome = "gaussian",
                     control_outcome = controlOut(penalty = "SCAD"),
                     control_inference = controlInf(vars_selection = TRUE))

cbind(mi_sample_scad$output,mi_sample_scad$confidence_interval)
```

We can change to nearest neighbour imputation estimator but note that we use all X not predictive mean matching.

```{r mi-sample-nn}
mi_sample_nn <- nonprob(outcome = Y ~ X3 + X4 + X5 + X6,
                        data = sample_B,
                        svydesign = sample_A_svy_cal,
                        method_outcome = "nn",
                        family_outcome = "gaussian",
                        control_outcome = controlOut(k = 3))

cbind(mi_sample_nn$output,mi_sample_nn$confidence_interval)
```
We can specify variance to boostrap

```{r mi-sample-nn-boot}
mi_sample_nn <- nonprob(outcome = Y ~ X3 + X4 + X5 + X6,
                        data = sample_B,
                        svydesign = sample_A_svy_cal,
                        method_outcome = "nn",
                        family_outcome = "gaussian",
                        control_outcome = controlOut(k = 3),
                        control_inference = controlInf(var_method = "bootstrap", num_boot = 100))

cbind(mi_sample_nn$output,mi_sample_nn$confidence_interval)
```
# Doubly robust estimator

Finally, we present [doubly robust estimator](https://ncn-foreigners.github.io/nonprobsvy-book/dr.html) under different settings. 

## Only population information is available

Consider the case when only population information is available

```{r dr-pop-totals}
dr_logit_poptotals <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                              outcome = Y ~ X1 + X2 + X3 + X4,
                              data = sample_B,
                              pop_totals = X_totals[1:5],
                              method_selection = "logit")

cbind(dr_logit_poptotals$output,dr_logit_poptotals$confidence_interval)
```
We can apply `gee` with `h=1` 

```{r dr-pop-totals-gee}
dr_logit_poptotals_gee <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                                  outcome = Y ~ X1 + X2 + X3 + X4,
                                  data = sample_B,
                                  pop_totals = X_totals[1:5],
                                  method_selection = "logit",
                                  control_selection = controlSel(est_method_sel = "gee", h = 1))

cbind(dr_logit_poptotals_gee$output,dr_logit_poptotals_gee$confidence_interval)
```
Finally, we can coduct variable selection

```{r dr-pop-totals-scad}
dr_logit_poptotals_scad <- nonprob(selection = ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                                   outcome = Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                                   data = sample_B,
                                   pop_totals = X_totals[1:11],
                                   method_selection = "logit",
                                   control_inference = controlInf(vars_selection = TRUE))

cbind(dr_logit_poptotals_scad$output,dr_logit_poptotals_scad$confidence_interval)
```

Note that we apply union of variables after variable selection.

## Probability sample is available

Now consider situation when probability sample is available

```{r dr-sample}
dr_logit_sample <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                           outcome = Y ~ X1 + X2 + X3 + X4,
                           data = sample_B,
                           svydesign = sample_A_svy_cal,
                           method_selection = "logit")

cbind(dr_logit_sample$output,dr_logit_sample$confidence_interval)
```

Now use `gee` with `h=1` with bootstrap.

```{r dr-sample-gee}
dr_logit_sample_gee <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                               outcome = Y ~ X1 + X2 + X3 + X4,
                               data = sample_B,
                               svydesign = sample_A_svy_cal,
                               method_selection = "logit",
                               control_selection = controlSel(est_method_sel = "gee", h = 1),
                               control_inference = controlInf(var_method = "bootstrap", num_boot = 100))

cbind(dr_logit_sample_gee$output,dr_logit_sample_gee$confidence_interval)
```
We can also use bias minimization method as proposed in @yang2020 by setting `est_method_sel = "mm"`.

```{r dr-sample-bmm}
dr_logit_sample_mm <- nonprob(selection = ~ X1 + X2 + X3 + X4,
                               outcome = Y ~ X1 + X2 + X3 + X4,
                               data = sample_B,
                               svydesign = sample_A_svy_cal,
                               method_selection = "logit",
                               control_selection = controlSel(est_method_sel = "mm", h = 2),
                               control_inference = controlInf(var_method = "bootstrap", num_boot = 100))

cbind(dr_logit_sample_mm$output,dr_logit_sample_mm$confidence_interval)
```

We can apply bias variable selection (`SCAD`) [not working]

```{r dr-sample-scad, eval = F}
dr_logit_sample_scad <- nonprob(selection = ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                                outcome = Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                                data = sample_B,
                                svydesign = sample_A_svy_cal,
                                method_selection = "logit",
                                control_selection = controlSel(penalty = "SCAD"),
                                control_inference = controlInf(vars_selection = TRUE))

cbind(dr_logit_sample_scad$output, dr_logit_sample_scad$confidence_interval)
```

Finally, we can apply method proposed by  @yang2020, i.e. variable selection using SCAD and bias minimization after selection.

```{r dr-sample-mm-scad}
dr_logit_sample_mm_scad <- nonprob(selection = ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                                    outcome = Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
                                    data = sample_B,
                                    svydesign = sample_A_svy_cal,
                                    method_selection = "logit",
                                    control_selection = controlSel(penalty = "SCAD", est_method_sel = "mm"),
                                    control_inference = controlInf(vars_selection = TRUE))

cbind(dr_logit_sample_mm_scad$output, dr_logit_sample_mm_scad$confidence_interval)
```

# Summary

Now combine estimates from all models

```{r table-with-results}
tab_res <- rbind(
  cbind(est="ipw with poptotals", ipw_logit_poptotals$output,ipw_logit_poptotals$confidence_interval),
  cbind(est="ipw with poptotals (gee h=1)", ipw_logit_poptotals_gee$output,ipw_logit_poptotals_gee$confidence_interval),
  cbind(est="ipw with poptotals SCAD", ipw_logit_poptotals_scad$output,ipw_logit_poptotals_scad$confidence_interval),
  cbind(est="ipw with sample", ipw_logit_sample$output,ipw_logit_sample$confidence_interval),
  cbind(est="ipw with sample (gee h=1)" , ipw_logit_sample_gee$output,ipw_logit_sample_gee$confidence_interval),
  cbind(est="ipw with sample (gee h=1 bootstrap)" , ipw_logit_sample_gee_boot$output,ipw_logit_sample_gee_boot$confidence_interval),
  cbind(est="ipw with sample SCAD" , ipw_logit_sample_scad$output,ipw_logit_sample_scad$confidence_interval),
  cbind(est="mi with poptotals" , mi_poptotals$output,mi_poptotals$confidence_interval),
  cbind(est="mi with sample (glm)" , mi_sample$output,mi_sample$confidence_interval),
  cbind(est="mi with sample (nn)" , mi_sample_nn$output,mi_sample_nn$confidence_interval),
  cbind(est="dr with poptotals" , dr_logit_poptotals$output,dr_logit_poptotals$confidence_interval),
  cbind(est="dr with poptotals (gee h=1)" , dr_logit_poptotals_gee$output,dr_logit_poptotals_gee$confidence_interval),
  cbind(est="dr with poptotals SCAD" , dr_logit_poptotals_scad$output,dr_logit_poptotals_scad$confidence_interval),
  cbind(est="dr with sample (glm)" , dr_logit_sample$output,dr_logit_sample$confidence_interval),
  cbind(est="dr with sample (gee h=1)" , dr_logit_sample_gee$output,dr_logit_sample_gee$confidence_interval),
  cbind(est="dr with sample (bias min)" , dr_logit_sample_mm$output,dr_logit_sample_mm$confidence_interval),
  cbind(est="dr with sample (bias min) SCAD", dr_logit_sample_mm_scad$output, dr_logit_sample_mm_scad$confidence_interval)
)

tab_res
```
Plot the results

```{r plot-table}
ggplot(data = tab_res, aes(x = est, y = mean, ymin = lower_bound, ymax = upper_bound)) +
  geom_point() +
  geom_pointrange() +
  geom_hline(yintercept = y_true, linetype = "dashed", color = "red") + 
  coord_flip()
```

# Literature

