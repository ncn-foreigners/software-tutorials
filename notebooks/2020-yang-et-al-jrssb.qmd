---
title: "Short software tutorial on `nonprobsvy` package -- replicating results from the Yang et al. (2020)"
author: Maciej BerÄ™sewicz
format: 
  html:
    number-sections: true
    self-contained: true
    toc: true
    df-print: kable
lang: en
bibliography: references.bib
biblio-style: apalike
execute: 
  warning: false
  cache: false
  message: false
---


# Basic information

## Theory

This notebook is designed to replicate results from the paper

```
Yang, S., Kim, J. K., & Song, R. (2020). Doubly robust inference
when combining probability and non-probability samples with high
dimensional data. Journal of the Royal Statistical Society. Series
B, Statistical Methodology, 82(2), 445.
```

We generate the data using the following recipe from section 6 of this paper:

+ $N=10000$  -- population size,
+ $p=50$ -- number of $X_p$ variables where $p-1$ were generated from $N(0,1)$ distribution,
+ $A$ -- probability sample about $n_A \approx 500$,
+ $B$ -- non-probability sample of size about $n_B \approx 2000$,
+ selection to probability sample $A \propto 0.25 + |X_{1i}| + 0.03|Y_i|$ (hence 4 probability samples),
+ non-probability selected using the following definitions
    + $\text{logit}(\pi_{B,i}) =\mathbf{\alpha}^TX_i$ (model PSM I), or   
    + $\text{logit}(\pi_{B,i}) = (3.5 + \mathbf{\alpha}^T(\log(\mathbf{X}_i)^2) - \sin(X_{3i} + X_{4i}) - X_{5i} - X_{6i})$ (model PSM II),
    + where $\mathbf{\alpha}=(0,0,0,3,3,3,3,0,...,0)^T$,
+ $Y$ generated according to the following model: 
    + continous:
        + $Y_i = 1 + \exp(3\sin(\mathbf{\beta}^T\mathbf{X}_i)) + X_{5i} + X_{6i} + \epsilon$ (model OM I), or
        + $Y_i = \mathbf{\beta}^T\mathbf{X}_i + \epsilon$ (model OM II), 
        + where $\mathbf{\beta}=(1,0,0,1,1,1,1,0,...,0)^T$
    + binary:
        + $Y_i \sim \text{Ber}(\pi_Y(X))$ with $\text{logit}(\pi_Y(X)) = \mathbf{\beta}^TX_i$ (model OM III),
        + $Y_i \sim \text{Ber}(\pi_Y(X))$ with $\text{logit}(\pi_Y(X)) = 2 - \log((\mathbf{\beta}^TX_i)^2) + 2X_{5,i}+2X_{6,i}$ (model OM IV),
        + where $\mathbf{\beta}=(1,0,0,1,1,1,1,0,...,0)^T$


Yang et al. (2020) consider the following estimators:


## Generate data

Load packages

```{r}
library(nonprobsvy)
library(survey)
library(sampling)
library(ggplot2)
```

Package version

```{r}
packageVersion("nonprobsvy")
```

Generate data according to the theory presented above

```{r generate-data}
seed_for_sim <- 2024
set.seed(seed_for_sim)

N <- 10000
n_A <- 500
p <- 50
alpha_vec1 <- c(-2, 1, 1, 1, 1, rep(0, p - 5))
alpha_vec2 <- c(0, 0, 0, 3, 3, 3, 3, rep(0, p - 7))
beta_vec <- c(1, 0, 0, 1, 1, 1, 1, rep(0, p - 7))

## generate X
X <- cbind(
  "(Intercept)" = 1, 
  matrix(
    rnorm(N * (p - 1)), 
    nrow = N, byrow = TRUE, 
    dimnames = list(NULL, paste0("X", 1:(p - 1)))
  )
)
X_formula  <- as.formula(paste("~", paste0("X", 1:(p - 1), collapse = " + ")))

## generate Y
Y_11 <- as.numeric(X %*% beta_vec) +  rnorm(N) ## OM I: linear model
Y_12 <- 1 + exp(3*sin(as.numeric(X %*% beta_vec))) + X[, "X5"] + X[, "X6"] + rnorm(N) ## OM II: nonlinear model
pi_Y_21 <- plogis(as.numeric(X %*% beta_vec)) ## OM III: linear model for binary Y
pi_Y_22 <- plogis(2 - log((X %*% beta_vec)^2) - 2*X[,"X5"] + 2*X[, "X6"]) ## OM IV: nonlinear model for binary Y
Y_21 <- rbinom(N, 1, prob = pi_Y_21)
Y_22 <- rbinom(N, 1, prob = pi_Y_22)

## generate probs
pi_A_Y11 <- inclusionprobabilities(0.25 + abs(X[, "X1"]) + 0.03*abs(Y_11), n_A)
pi_A_Y12 <- inclusionprobabilities(0.25 + abs(X[, "X1"]) + 0.03*abs(Y_12), n_A)
pi_A_Y21 <- inclusionprobabilities(0.25 + abs(X[, "X1"]) + 0.03*abs(Y_21), n_A)
pi_A_Y22 <- inclusionprobabilities(0.25 + abs(X[, "X1"]) + 0.03*abs(Y_22), n_A)

pi_B1 <- plogis(as.numeric(X %*% alpha_vec1)) ## PSM I: linear probability
pi_B2 <- plogis(3.5 + as.numeric(log(X^2) %*% alpha_vec2) - sin(X[, "X3"] + X[, "X4"]) - X[,"X5"] + X[, "X6"]) ## PSM II: nonlinear 


## generate data
population <- data.frame(pi_A_Y11, pi_A_Y12, pi_A_Y21, pi_A_Y22, Y_11, Y_12, Y_21, Y_22, X[, 2:p])

controls_inf_paper <- control_inf(vars_selection = TRUE, 
                                  bias_correction = TRUE,
                                  vars_combine = TRUE)
control_sel_paper <- control_sel(nfolds = 5, nlambda = 5)

control_sel_paper_h <- control_sel(nfolds = 5, 
                                   nlambda = 5, 
                                   est_method = "gee",
                                   nleqslv_xscalm = "auto"
                                   )

```

## Single run

### Generate samples

Now, we provide a single run. First, we generate 4 probability samples.

```{r probability-survey}
set.seed(seed_for_sim)
flag_A_Y11 <- UPpoisson(pik = pi_A_Y11)
flag_A_Y12 <- UPpoisson(pik = pi_A_Y12)
flag_A_Y21 <- UPpoisson(pik = pi_A_Y21)
flag_A_Y22 <- UPpoisson(pik = pi_A_Y22)
  
sample_A_svy_Y11 <- svydesign(ids = ~ 1, probs = ~ pi_A_Y11, pps = "brewer", data = population[flag_A_Y11 == 1, ])
sample_A_svy_Y12 <- svydesign(ids = ~ 1, probs = ~ pi_A_Y12, pps = "brewer", data = population[flag_A_Y12 == 1, ])
sample_A_svy_Y21 <- svydesign(ids = ~ 1, probs = ~ pi_A_Y21, pps = "brewer", data = population[flag_A_Y21 == 1, ])
sample_A_svy_Y22 <- svydesign(ids = ~ 1, probs = ~ pi_A_Y22, pps = "brewer", data = population[flag_A_Y22 == 1, ])
```

Next, we generate two samples based on `flag_B1` and `flag_B2`.

```{r nonprob-survey}
set.seed(seed_for_sim)
flag_B1 <- rbinom(N, 1, prob = pi_B1)
flag_B2 <- rbinom(N, 1, prob = pi_B2)

sample_B1 <- population[flag_B1 == 1, ]
sample_B2 <- population[flag_B2 == 1, ]
```

### Estimators under PSM I

Naive estimator.

```{r naive, eval = TRUE}
est_naive <- aggregate(cbind(Y_11,Y_12,Y_21,Y_22) ~ 1, sample_B1, mean)
est_naive
```

IPW with variable selection using SCAD penalty (note that this IPW is IPW with calibration constraints on selected variables).

```{r ipw-with-scad, eval = TRUE}
est_b1_ipw_y11 <- nonprob(selection = X_formula,
                          target = ~ Y_11,
                          data = sample_B1,
                          svydesign = sample_A_svy_Y11,
                          control_selection = control_sel_paper,
                          control_inference = control_inf(vars_selection = TRUE))
est_b1_ipw_y12 <- nonprob(selection = X_formula,
                          target = ~ Y_12,
                          data = sample_B1,
                          svydesign = sample_A_svy_Y12,
                          control_selection = control_sel_paper,
                          control_inference = control_inf(vars_selection = TRUE))
est_b1_ipw_y21 <- nonprob(selection = X_formula,
                          target = ~ Y_21,
                          data = sample_B1,
                          svydesign = sample_A_svy_Y21,
                          control_selection = control_sel_paper,
                          control_inference = control_inf(vars_selection = TRUE))
est_b1_ipw_y22 <- nonprob(selection = X_formula,
                          target = ~ Y_22,
                          data = sample_B1,
                          svydesign = sample_A_svy_Y22,
                          control_selection = control_sel_paper,
                          control_inference = control_inf(vars_selection = TRUE))
```


Mass imputation with SCAD penalty.

```{r mi-with-scad, eval = TRUE}
est_b1_glm_y11 <- nonprob(outcome = as.formula(paste("Y_11", X_formula)),
                          data = sample_B1,
                          svydesign = sample_A_svy_Y11,
                          method_outcome = "glm",
                          family_outcome = "gaussian",
                          control_inference = control_inf(vars_selection = T))
est_b1_glm_y12 <- nonprob(outcome = as.formula(paste("Y_12", X_formula)),
                          data = sample_B1,
                          svydesign = sample_A_svy_Y12,
                          method_outcome = "glm",
                          family_outcome = "gaussian",
                          control_inference = control_inf(vars_selection = T))
est_b1_glm_y21 <- nonprob(outcome = as.formula(paste("Y_21", X_formula)),
                          data = sample_B1,
                          svydesign = sample_A_svy_Y21,
                          method_outcome = "glm",
                          family_outcome = "binomial",
                          control_inference = control_inf(vars_selection = T))
est_b1_glm_y22 <- nonprob(outcome = as.formula(paste("Y_22", X_formula)),
                          data = sample_B1,
                          svydesign = sample_A_svy_Y22,
                          method_outcome = "glm",
                          family_outcome = "binomial",
                          control_inference = control_inf(vars_selection = T))
```

DR with bias minimization with union of variables after selection of variables with SCAD.

```{r dr-with-scad-mm, cache = TRUE, eval = TRUE}
est_b1_dr_y11 <- nonprob(outcome = as.formula(paste("Y_11", X_formula)),
                         selection = X_formula,
                         data = sample_B1,
                         svydesign = sample_A_svy_Y11,
                         method_outcome = "glm",
                         family_outcome = "gaussian",
                         control_selection = control_sel_paper_h,
                         control_inference = controls_inf_paper,
                         pop_size = N)
est_b1_dr_y12 <- nonprob(outcome = as.formula(paste("Y_12", X_formula)),
                         selection = X_formula,
                         data = sample_B1,
                         svydesign = sample_A_svy_Y12,
                         method_outcome = "glm",
                         family_outcome = "gaussian",
                         control_selection = control_sel_paper_h,
                         control_inference = controls_inf_paper,
                         pop_size = N)
est_b1_dr_y21 <- nonprob(outcome = as.formula(paste("Y_21", X_formula)),
                         selection = X_formula,
                         data = sample_B1,
                         svydesign = sample_A_svy_Y21,
                         method_outcome = "glm",
                         family_outcome = "binomial",
                         control_selection = control_sel_paper_h,
                         control_inference = controls_inf_paper,
                         pop_size = N)
est_b1_dr_y22 <- nonprob(outcome = as.formula(paste("Y_22", X_formula)),
                         selection = X_formula,
                         data = sample_B1,
                         svydesign = sample_A_svy_Y22,
                         method_outcome = "glm",
                         family_outcome = "binomial",
                         control_selection = control_sel_paper_h,
                         control_inference = controls_inf_paper,
                         pop_size = N)
```

Compare results

```{r, eval = T}
results <- rbind(
  cbind(est_b1_ipw_y11$output,est_b1_ipw_y11$confidence_interval),
  cbind(est_b1_ipw_y12$output,est_b1_ipw_y12$confidence_interval),
  cbind(est_b1_ipw_y21$output,est_b1_ipw_y21$confidence_interval),
  cbind(est_b1_ipw_y22$output,est_b1_ipw_y22$confidence_interval),
  cbind(est_b1_glm_y11$output,est_b1_glm_y11$confidence_interval),
  cbind(est_b1_glm_y12$output,est_b1_glm_y12$confidence_interval),
  cbind(est_b1_glm_y21$output,est_b1_glm_y21$confidence_interval),
  cbind(est_b1_glm_y22$output,est_b1_glm_y22$confidence_interval),
  cbind(est_b1_dr_y11$output,est_b1_dr_y11$confidence_interval),
  cbind(est_b1_dr_y12$output,est_b1_dr_y12$confidence_interval),
  cbind(est_b1_dr_y21$output,est_b1_dr_y21$confidence_interval),
  cbind(est_b1_dr_y22$output,est_b1_dr_y22$confidence_interval),
  data.frame(mean = unname(t(est_naive)), SE = NA, lower_bound = NA, upper_bound = NA)
)
rownames(results) <- NULL
results$y <- rep(c("Y_11", "Y_12", "Y_21", "Y_22"), rep = 4)
results$estim <- rep(c("IPW", "MI", "DR", "Naive"), each = 4)
results$estim <- factor(results$estim, c("Naive", "IPW", "MI", "DR"))
results$true  <- rep(c(mean(Y_11), mean(Y_12), mean(Y_21), mean(Y_22)), rep = 6)
results <- results[, c("y", "estim", "mean", "SE", "lower_bound", "upper_bound", "true")]
results <- results[order(results$y, results$estim),]
results
```
Plot results from one go

```{r warning=FALSE}
ggplot(data = results, aes(x = estim, y = mean, ymin = lower_bound, ymax = upper_bound)) +
  geom_point() + 
  geom_pointrange() +
  geom_hline(aes(yintercept = true), color = "red", linetype = "dashed") + 
  facet_wrap(~y, scales = "free_x", labeller = labeller(y = c("Y_11" = "Y_11 (gaussian lin)",
                                                              "Y_12" = "Y_12 (gaussian nonlin)",
                                                              "Y_21" = "Y_21 (binomial lin)",
                                                              "Y_22" = "Y_22 (binomial nonlin)"))) +
  coord_flip() +
  labs(y = "Mean", x = "Estimator")
```


### Estimators under PSM II

Naive estimator.

```{r naive-ps2, eval = TRUE}
est_naive_b2 <- aggregate(cbind(Y_11,Y_12,Y_21,Y_22) ~ 1, sample_B2, mean)
```

IPW with variable selection using SCAD penalty (note that this IPW is IPW with calibration constraints on selected variables).

```{r ipw-with-scad-ps2, eval = TRUE}
est_b2_ipw_y11 <- nonprob(selection = X_formula,
                          target = ~ Y_11,
                          data = sample_B2,
                          svydesign = sample_A_svy_Y11,
                          control_selection = control_sel_paper,
                          control_inference = control_inf(vars_selection = TRUE))
est_b2_ipw_y12 <- nonprob(selection = X_formula,
                          target = ~ Y_12,
                          data = sample_B2,
                          svydesign = sample_A_svy_Y12,
                          control_selection = control_sel_paper,
                          control_inference = control_inf(vars_selection = TRUE))
est_b2_ipw_y21 <- nonprob(selection = X_formula,
                          target = ~ Y_21,
                          data = sample_B2,
                          svydesign = sample_A_svy_Y21,
                          control_selection = control_sel_paper,
                          control_inference = control_inf(vars_selection = TRUE))
est_b2_ipw_y22 <- nonprob(selection = X_formula,
                          target = ~ Y_22,
                          data = sample_B2,
                          svydesign = sample_A_svy_Y22,
                          control_selection = control_sel_paper,
                          control_inference = control_inf(vars_selection = TRUE))
```


Mass imputation with SCAD penalty.

```{r mi-with-scad-ps2, eval = TRUE}
est_b2_glm_y11 <- nonprob(outcome = as.formula(paste("Y_11", X_formula)),
                          data = sample_B2,
                          svydesign = sample_A_svy_Y11,
                          method_outcome = "glm",
                          family_outcome = "gaussian",
                          control_inference = control_inf(vars_selection = T))
est_b2_glm_y12 <- nonprob(outcome = as.formula(paste("Y_12", X_formula)),
                          data = sample_B2,
                          svydesign = sample_A_svy_Y12,
                          method_outcome = "glm",
                          family_outcome = "gaussian",
                          control_inference = control_inf(vars_selection = T))
est_b2_glm_y21 <- nonprob(outcome = as.formula(paste("Y_21", X_formula)),
                          data = sample_B2,
                          svydesign = sample_A_svy_Y21,
                          method_outcome = "glm",
                          family_outcome = "binomial",
                          control_inference = control_inf(vars_selection = T))
est_b2_glm_y22 <- nonprob(outcome = as.formula(paste("Y_22", X_formula)),
                          data = sample_B2,
                          svydesign = sample_A_svy_Y22,
                          method_outcome = "glm",
                          family_outcome = "binomial",
                          control_inference = control_inf(vars_selection = T))
```

DR with bias minimization with union of variables after selection of variables with SCAD.

```{r dr-with-scad-ps2, cache = TRUE, eval = TRUE}
est_b2_dr_y11 <- nonprob(outcome = as.formula(paste("Y_11", X_formula)),
                         selection = X_formula,
                         data = sample_B2,
                         svydesign = sample_A_svy_Y11,
                         method_outcome = "glm",
                         family_outcome = "gaussian",
                         control_selection = control_sel_paper_h,
                         control_inference = controls_inf_paper,
                         pop_size = N)
est_b2_dr_y12 <- nonprob(outcome = as.formula(paste("Y_12", X_formula)),
                         selection = X_formula,
                         data = sample_B2,
                         svydesign = sample_A_svy_Y12,
                         method_outcome = "glm",
                         family_outcome = "gaussian",
                         control_selection = control_sel_paper_h,
                         control_inference = controls_inf_paper,
                         pop_size = N)
est_b2_dr_y21 <- nonprob(outcome = as.formula(paste("Y_21", X_formula)),
                         selection = X_formula,
                         data = sample_B2,
                         svydesign = sample_A_svy_Y21,
                         method_outcome = "glm",
                         family_outcome = "binomial",
                         control_selection = control_sel_paper_h,
                         control_inference = controls_inf_paper,
                         pop_size = N)
est_b2_dr_y22 <- nonprob(outcome = as.formula(paste("Y_22", X_formula)),
                         selection = X_formula,
                         data = sample_B2,
                         svydesign = sample_A_svy_Y22,
                         method_outcome = "glm",
                         family_outcome = "binomial",
                         control_selection = control_sel_paper_h,
                         control_inference = controls_inf_paper,
                         pop_size = N)
```


Compare results

```{r, eval = TRUE}
results <- rbind(
  cbind(est_b2_ipw_y11$output,est_b2_ipw_y11$confidence_interval),
  cbind(est_b2_ipw_y12$output,est_b2_ipw_y12$confidence_interval),
  cbind(est_b2_ipw_y21$output,est_b2_ipw_y21$confidence_interval),
  cbind(est_b2_ipw_y22$output,est_b2_ipw_y22$confidence_interval),
  cbind(est_b2_glm_y11$output,est_b2_glm_y11$confidence_interval),
  cbind(est_b2_glm_y12$output,est_b2_glm_y12$confidence_interval),
  cbind(est_b2_glm_y21$output,est_b2_glm_y21$confidence_interval),
  cbind(est_b2_glm_y22$output,est_b2_glm_y22$confidence_interval),
  cbind(est_b2_dr_y11$output, est_b2_dr_y11$confidence_interval),
  cbind(est_b2_dr_y12$output, est_b2_dr_y12$confidence_interval),
  cbind(est_b2_dr_y21$output, est_b2_dr_y21$confidence_interval),
  cbind(est_b2_dr_y22$output, est_b2_dr_y22$confidence_interval),
  data.frame(mean = unname(t(est_naive_b2)), SE = NA, lower_bound = NA, upper_bound = NA)
)
rownames(results) <- NULL
results$y <- rep(c("Y_11", "Y_12", "Y_21", "Y_22"), rep = 4)
results$estim <- rep(c("IPW", "MI", "DR", "Naive"), each = 4)
results$estim <- factor(results$estim, c("Naive", "IPW", "MI", "DR"))
results$true  <- rep(c(mean(Y_11), mean(Y_12), mean(Y_21), mean(Y_22)), rep = 6)
results <- results[, c("y", "estim", "mean", "SE", "lower_bound", "upper_bound", "true")]
results <- results[order(results$y, results$estim),]
results
```



Plot results from one go

```{r warning=FALSE}
ggplot(data = results, aes(x = estim, y = mean, ymin = lower_bound, ymax = upper_bound)) +
  geom_point() + 
  geom_pointrange() +
  geom_hline(aes(yintercept = true), color = "red", linetype = "dashed") + 
  facet_wrap(~y, scales = "free_x", labeller = labeller(y = c("Y_11" = "Y_11 (gaussian lin)",
                                                              "Y_12" = "Y_12 (gaussian nonlin)",
                                                              "Y_21" = "Y_21 (binomial lin)",
                                                              "Y_22" = "Y_22 (binomial nonlin)"))) +
  coord_flip() +
  labs(y = "Mean", x = "Estimator")
```

## B=500 simulation

